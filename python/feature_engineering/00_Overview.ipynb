{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cff42f68",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリング概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aff94d",
   "metadata": {},
   "source": [
    "## 本プロジェクトの目的\n",
    "\n",
    "機械学習のパフォーマンス改善に向けて重要な特徴量エンジニアリングの手法を，実装例を交えて紹介する．  \n",
    "主に特徴量エンジニアリングについて述べるが，一部特徴量選択についても触れる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb20c1",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリングとは\n",
    "\n",
    "機械学習における特徴量とは，分析対象を測定することが可能な変数を指す．データセットでは特徴量は列として表記されることが多い．\n",
    "\n",
    "データセットに含める特徴量の質が，機械学習モデルの精度に影響し，ひいては機械学習を活用する場合に得るインサイトの質に大きく影響する．\n",
    "\n",
    "データセットの質を改善する為に，特徴量選択や特徴量エンジニアリングが実施される．  \n",
    "特徴量選択は分析対象に関連する特徴量に重点を置き，無関係な特徴量を取り除くプロセスを指す．特徴量エンジニアリングは，既存の特徴量をもとに新たな特徴量を構築してデータセットに追加することを指す．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895573ac",
   "metadata": {},
   "source": [
    "## 特徴量選択と特徴量エンジニアリングの具体例\n",
    "\n",
    "特徴エンジニアリングの手法の詳細は他のNotebookに記載するが，本節では特徴量選択と特徴量エンジニアリングの違いを説明する為の具体例を示す．\n",
    "\n",
    "データセットはFlood Modeling Datasetを使用し，論文[Time Series Extrinsic Regression](https://arxiv.org/abs/2006.12672)のSVR Optimisedの条件に対してtsfreshによる特徴量選択及び特徴量エンジニアリングを試行する．\n",
    "\n",
    "学習パラメータは論文通り，下記パラメータに対して3-Folds Cross ValidationのGridSearchのベストモデルを採用する．\n",
    "\n",
    "|Parameters|Values|\n",
    "|:--|:--|\n",
    "|Kernel|RBF, Sigmoid|\n",
    "|gamma|0.001, 0.01, 0.1, 1|\n",
    "|C|0.1, 1, 10, 100|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86536f",
   "metadata": {},
   "source": [
    "### 実装例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055b80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ローカルモジュールの更新を自動で読み込む ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c62164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from tsfresh import extract_features\n",
    "from lib.dataloader.flood_modeling import load_flood_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a4ef5",
   "metadata": {},
   "source": [
    "#### データセットダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7d1719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset flood_modeling_datasets is already exist\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.exists(\"flood_modeling_datasets\")):\n",
    "    !mkdir -p \"flood_modeling_datasets\" ; \\\n",
    "        cd flood_modeling_datasets ; \\\n",
    "        wget \"https://zenodo.org/record/3902694/files/FloodModeling1_TEST.ts\" ; \\\n",
    "        wget \"https://zenodo.org/record/3902694/files/FloodModeling1_TRAIN.ts\" ; \\\n",
    "        ls\n",
    "else:\n",
    "    print('[INFO] Dataset flood_modeling_datasets is already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e2195c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 266)\n",
      "(471,)\n",
      "(202, 266)\n",
      "(202,)\n"
     ]
    }
   ],
   "source": [
    "train_ts = os.path.join('flood_modeling_datasets', 'FloodModeling1_TRAIN.ts')\n",
    "test_ts = os.path.join('flood_modeling_datasets', 'FloodModeling1_TEST.ts')\n",
    "x_train, y_train, x_test, y_test = load_flood_modeling(train_ts, test_ts)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913dd20",
   "metadata": {},
   "source": [
    "#### 3-Flods Cross ValidationとGridSearchでモデルを学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a88b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Best params: {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "[INFO] Best score: 0.04293317276271991\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return rmse\n",
    "\n",
    "params = {\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'C': [0.1, 1, 10, 100]\n",
    "}\n",
    "model_svr = GridSearchCV(\n",
    "    svm.SVR(),\n",
    "    params,\n",
    "    cv=KFold(n_splits=3, shuffle=True, random_state=1234),\n",
    "    scoring=make_scorer(rmse, greater_is_better=False))\n",
    "model_svr.fit(x_train, y_train)\n",
    "\n",
    "print('[INFO] Best params: {}'.format(model_svr.best_params_))\n",
    "print('[INFO] Best score: {}'.format(-model_svr.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608b1b3",
   "metadata": {},
   "source": [
    "#### テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3deaaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046303583075482053\n"
     ]
    }
   ],
   "source": [
    "prediction = model_svr.predict(x_test)\n",
    "print(rmse(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256c864",
   "metadata": {},
   "source": [
    "論文[Time Series Extrinsic Regression](https://arxiv.org/abs/2006.12672)の実験結果がRMSE=0.05なので，再現できた．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5452a4",
   "metadata": {},
   "source": [
    "#### tsfreshで時系列データから特徴量を抽出(特徴量エンジニアリング)\n",
    "\n",
    "tsfreshを用いて特徴量を抽出する為に，時系列データを整然データに整形する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd0dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125286, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.147225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.178263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample         A\n",
       "0       0  0.058010\n",
       "1       0  0.104612\n",
       "2       0  0.147225\n",
       "3       0  0.178263\n",
       "4       0  0.191615"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train = pd.DataFrame(x_train.T)\n",
    "df_x_train_melt = df_x_train.melt(var_name='sample', value_name='A')\n",
    "print(df_x_train_melt.shape)\n",
    "df_x_train_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b2f0f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:06<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(471, 787)\n",
      "(471, 775)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A__variance_larger_than_standard_deviation</th>\n",
       "      <th>A__has_duplicate_max</th>\n",
       "      <th>A__has_duplicate_min</th>\n",
       "      <th>A__has_duplicate</th>\n",
       "      <th>A__sum_values</th>\n",
       "      <th>A__abs_energy</th>\n",
       "      <th>A__mean_abs_change</th>\n",
       "      <th>A__mean_change</th>\n",
       "      <th>A__mean_second_derivative_central</th>\n",
       "      <th>A__median</th>\n",
       "      <th>...</th>\n",
       "      <th>A__fourier_entropy__bins_2</th>\n",
       "      <th>A__fourier_entropy__bins_3</th>\n",
       "      <th>A__fourier_entropy__bins_5</th>\n",
       "      <th>A__fourier_entropy__bins_10</th>\n",
       "      <th>A__fourier_entropy__bins_100</th>\n",
       "      <th>A__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_7__tau_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.562985</td>\n",
       "      <td>154.196861</td>\n",
       "      <td>0.053672</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188113</td>\n",
       "      <td>0.275463</td>\n",
       "      <td>0.378572</td>\n",
       "      <td>0.543862</td>\n",
       "      <td>0.771130</td>\n",
       "      <td>0.784683</td>\n",
       "      <td>1.055961</td>\n",
       "      <td>1.353449</td>\n",
       "      <td>1.662556</td>\n",
       "      <td>1.950983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.868674</td>\n",
       "      <td>145.591326</td>\n",
       "      <td>0.308707</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163982</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>0.262742</td>\n",
       "      <td>0.329196</td>\n",
       "      <td>1.734991</td>\n",
       "      <td>1.581074</td>\n",
       "      <td>2.684640</td>\n",
       "      <td>3.707707</td>\n",
       "      <td>4.371126</td>\n",
       "      <td>4.689947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.257011</td>\n",
       "      <td>114.038367</td>\n",
       "      <td>0.218197</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>1.329262</td>\n",
       "      <td>1.061334</td>\n",
       "      <td>1.523338</td>\n",
       "      <td>1.882738</td>\n",
       "      <td>2.060085</td>\n",
       "      <td>2.144009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.636373</td>\n",
       "      <td>318.370109</td>\n",
       "      <td>0.175128</td>\n",
       "      <td>-0.009807</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138228</td>\n",
       "      <td>0.217718</td>\n",
       "      <td>0.375938</td>\n",
       "      <td>0.516731</td>\n",
       "      <td>1.844222</td>\n",
       "      <td>1.333710</td>\n",
       "      <td>2.165619</td>\n",
       "      <td>2.864823</td>\n",
       "      <td>3.334014</td>\n",
       "      <td>3.653658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.368367</td>\n",
       "      <td>180.487523</td>\n",
       "      <td>0.094849</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138228</td>\n",
       "      <td>0.190068</td>\n",
       "      <td>0.299591</td>\n",
       "      <td>0.418924</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>1.146120</td>\n",
       "      <td>1.706036</td>\n",
       "      <td>2.275920</td>\n",
       "      <td>2.831335</td>\n",
       "      <td>3.316521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A__variance_larger_than_standard_deviation  A__has_duplicate_max  \\\n",
       "0                                         0.0                   0.0   \n",
       "1                                         0.0                   0.0   \n",
       "2                                         0.0                   0.0   \n",
       "3                                         1.0                   0.0   \n",
       "4                                         0.0                   0.0   \n",
       "\n",
       "   A__has_duplicate_min  A__has_duplicate  A__sum_values  A__abs_energy  \\\n",
       "0                   1.0               1.0      75.562985     154.196861   \n",
       "1                   1.0               1.0      98.868674     145.591326   \n",
       "2                   1.0               1.0      50.257011     114.038367   \n",
       "3                   1.0               1.0     107.636373     318.370109   \n",
       "4                   1.0               1.0      91.368367     180.487523   \n",
       "\n",
       "   A__mean_abs_change  A__mean_change  A__mean_second_derivative_central  \\\n",
       "0            0.053672       -0.000219                          -0.000088   \n",
       "1            0.308707       -0.001210                           0.000607   \n",
       "2            0.218197       -0.000646                           0.000182   \n",
       "3            0.175128       -0.009807                          -0.000205   \n",
       "4            0.094849       -0.000604                           0.000303   \n",
       "\n",
       "   A__median  ...  A__fourier_entropy__bins_2  A__fourier_entropy__bins_3  \\\n",
       "0        0.0  ...                    0.188113                    0.275463   \n",
       "1        0.0  ...                    0.163982                    0.220352   \n",
       "2        0.0  ...                    0.045395                    0.045395   \n",
       "3        0.0  ...                    0.138228                    0.217718   \n",
       "4        0.0  ...                    0.138228                    0.190068   \n",
       "\n",
       "   A__fourier_entropy__bins_5  A__fourier_entropy__bins_10  \\\n",
       "0                    0.378572                     0.543862   \n",
       "1                    0.262742                     0.329196   \n",
       "2                    0.090729                     0.136002   \n",
       "3                    0.375938                     0.516731   \n",
       "4                    0.299591                     0.418924   \n",
       "\n",
       "   A__fourier_entropy__bins_100  A__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                      0.771130                                    0.784683   \n",
       "1                      1.734991                                    1.581074   \n",
       "2                      1.329262                                    1.061334   \n",
       "3                      1.844222                                    1.333710   \n",
       "4                      0.999920                                    1.146120   \n",
       "\n",
       "   A__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                    1.055961   \n",
       "1                                    2.684640   \n",
       "2                                    1.523338   \n",
       "3                                    2.165619   \n",
       "4                                    1.706036   \n",
       "\n",
       "   A__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                    1.353449   \n",
       "1                                    3.707707   \n",
       "2                                    1.882738   \n",
       "3                                    2.864823   \n",
       "4                                    2.275920   \n",
       "\n",
       "   A__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                    1.662556   \n",
       "1                                    4.371126   \n",
       "2                                    2.060085   \n",
       "3                                    3.334014   \n",
       "4                                    2.831335   \n",
       "\n",
       "   A__permutation_entropy__dimension_7__tau_1  \n",
       "0                                    1.950983  \n",
       "1                                    4.689947  \n",
       "2                                    2.144009  \n",
       "3                                    3.653658  \n",
       "4                                    3.316521  \n",
       "\n",
       "[5 rows x 775 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train_melt_ef = extract_features(df_x_train_melt, column_id='sample')\n",
    "print(df_x_train_melt_ef.shape)\n",
    "df_x_train_melt_ef.dropna(axis=1, inplace=True)\n",
    "print(df_x_train_melt_ef.shape)\n",
    "df_x_train_melt_ef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd727b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53732, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.190118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.278452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.364941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.446354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.519787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample         A\n",
       "0       0  0.190118\n",
       "1       0  0.278452\n",
       "2       0  0.364941\n",
       "3       0  0.446354\n",
       "4       0  0.519787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_test = pd.DataFrame(x_test.T)\n",
    "df_x_test_melt = df_x_test.melt(var_name='sample', value_name='A')\n",
    "print(df_x_test_melt.shape)\n",
    "df_x_test_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d5424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:03<00:00, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 787)\n",
      "(202, 775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A__variance_larger_than_standard_deviation</th>\n",
       "      <th>A__has_duplicate_max</th>\n",
       "      <th>A__has_duplicate_min</th>\n",
       "      <th>A__has_duplicate</th>\n",
       "      <th>A__sum_values</th>\n",
       "      <th>A__abs_energy</th>\n",
       "      <th>A__mean_abs_change</th>\n",
       "      <th>A__mean_change</th>\n",
       "      <th>A__mean_second_derivative_central</th>\n",
       "      <th>A__median</th>\n",
       "      <th>...</th>\n",
       "      <th>A__fourier_entropy__bins_2</th>\n",
       "      <th>A__fourier_entropy__bins_3</th>\n",
       "      <th>A__fourier_entropy__bins_5</th>\n",
       "      <th>A__fourier_entropy__bins_10</th>\n",
       "      <th>A__fourier_entropy__bins_100</th>\n",
       "      <th>A__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>A__permutation_entropy__dimension_7__tau_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.548151</td>\n",
       "      <td>416.902740</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>0.155665</td>\n",
       "      <td>0.235155</td>\n",
       "      <td>0.339942</td>\n",
       "      <td>0.495930</td>\n",
       "      <td>0.761174</td>\n",
       "      <td>0.990888</td>\n",
       "      <td>1.216844</td>\n",
       "      <td>1.448576</td>\n",
       "      <td>1.682238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.714169</td>\n",
       "      <td>189.995101</td>\n",
       "      <td>0.300888</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.254093</td>\n",
       "      <td>2.148727</td>\n",
       "      <td>0.934982</td>\n",
       "      <td>1.469652</td>\n",
       "      <td>1.897610</td>\n",
       "      <td>2.165799</td>\n",
       "      <td>2.283179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.983586</td>\n",
       "      <td>97.945542</td>\n",
       "      <td>0.221572</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110453</td>\n",
       "      <td>0.233137</td>\n",
       "      <td>0.345796</td>\n",
       "      <td>0.529060</td>\n",
       "      <td>2.024522</td>\n",
       "      <td>1.253760</td>\n",
       "      <td>2.019174</td>\n",
       "      <td>2.595891</td>\n",
       "      <td>2.896423</td>\n",
       "      <td>3.032420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.456523</td>\n",
       "      <td>189.393081</td>\n",
       "      <td>0.083508</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291459</td>\n",
       "      <td>0.541661</td>\n",
       "      <td>0.699205</td>\n",
       "      <td>0.942941</td>\n",
       "      <td>1.426901</td>\n",
       "      <td>0.816907</td>\n",
       "      <td>1.166416</td>\n",
       "      <td>1.486912</td>\n",
       "      <td>1.816094</td>\n",
       "      <td>2.150398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.217469</td>\n",
       "      <td>394.718757</td>\n",
       "      <td>0.183493</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.170467</td>\n",
       "      <td>0.472096</td>\n",
       "      <td>1.458402</td>\n",
       "      <td>2.428749</td>\n",
       "      <td>3.335742</td>\n",
       "      <td>3.896036</td>\n",
       "      <td>4.204995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A__variance_larger_than_standard_deviation  A__has_duplicate_max  \\\n",
       "0                                         1.0                   0.0   \n",
       "1                                         0.0                   0.0   \n",
       "2                                         0.0                   0.0   \n",
       "3                                         0.0                   0.0   \n",
       "4                                         1.0                   0.0   \n",
       "\n",
       "   A__has_duplicate_min  A__has_duplicate  A__sum_values  A__abs_energy  \\\n",
       "0                   1.0               1.0     138.548151     416.902740   \n",
       "1                   1.0               1.0      64.714169     189.995101   \n",
       "2                   1.0               1.0      60.983586      97.945542   \n",
       "3                   1.0               1.0      54.456523     189.393081   \n",
       "4                   1.0               1.0     153.217469     394.718757   \n",
       "\n",
       "   A__mean_abs_change  A__mean_change  A__mean_second_derivative_central  \\\n",
       "0            0.054970       -0.000717                          -0.000167   \n",
       "1            0.300888       -0.001674                          -0.003694   \n",
       "2            0.221572       -0.003128                           0.001570   \n",
       "3            0.083508       -0.000045                          -0.000252   \n",
       "4            0.183493       -0.000785                           0.000152   \n",
       "\n",
       "   A__median  ...  A__fourier_entropy__bins_2  A__fourier_entropy__bins_3  \\\n",
       "0   0.000000  ...                    0.079983                    0.155665   \n",
       "1   0.000000  ...                    0.045395                    0.045395   \n",
       "2   0.000000  ...                    0.110453                    0.233137   \n",
       "3   0.000000  ...                    0.291459                    0.541661   \n",
       "4   0.002127  ...                    0.079983                    0.090729   \n",
       "\n",
       "   A__fourier_entropy__bins_5  A__fourier_entropy__bins_10  \\\n",
       "0                    0.235155                     0.339942   \n",
       "1                    0.090729                     0.254093   \n",
       "2                    0.345796                     0.529060   \n",
       "3                    0.699205                     0.942941   \n",
       "4                    0.090729                     0.170467   \n",
       "\n",
       "   A__fourier_entropy__bins_100  A__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                      0.495930                                    0.761174   \n",
       "1                      2.148727                                    0.934982   \n",
       "2                      2.024522                                    1.253760   \n",
       "3                      1.426901                                    0.816907   \n",
       "4                      0.472096                                    1.458402   \n",
       "\n",
       "   A__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                    0.990888   \n",
       "1                                    1.469652   \n",
       "2                                    2.019174   \n",
       "3                                    1.166416   \n",
       "4                                    2.428749   \n",
       "\n",
       "   A__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                    1.216844   \n",
       "1                                    1.897610   \n",
       "2                                    2.595891   \n",
       "3                                    1.486912   \n",
       "4                                    3.335742   \n",
       "\n",
       "   A__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                    1.448576   \n",
       "1                                    2.165799   \n",
       "2                                    2.896423   \n",
       "3                                    1.816094   \n",
       "4                                    3.896036   \n",
       "\n",
       "   A__permutation_entropy__dimension_7__tau_1  \n",
       "0                                    1.682238  \n",
       "1                                    2.283179  \n",
       "2                                    3.032420  \n",
       "3                                    2.150398  \n",
       "4                                    4.204995  \n",
       "\n",
       "[5 rows x 775 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_test_melt_ef = extract_features(df_x_test_melt, column_id='sample')\n",
    "print(df_x_test_melt_ef.shape)\n",
    "df_x_test_melt_ef.dropna(axis=1, inplace=True)\n",
    "print(df_x_test_melt_ef.shape)\n",
    "df_x_test_melt_ef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "144d10cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_x_train_melt_ef.columns == df_x_test_melt_ef.columns).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf736bd",
   "metadata": {},
   "source": [
    "時系列データ266sampleから787種の特徴量を抽出し，NaNを除去し最終的に775種の特徴量が得られた．  \n",
    "これらの特徴量を用いて，モデルを学習する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddca8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Best params: {'C': 0.1, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "[INFO] Best score: 0.05797496334968894\n"
     ]
    }
   ],
   "source": [
    "model_svr = GridSearchCV(\n",
    "    svm.SVR(),\n",
    "    params,\n",
    "    cv=KFold(n_splits=3, shuffle=True, random_state=1234),\n",
    "    scoring=make_scorer(rmse, greater_is_better=False))\n",
    "model_svr.fit(df_x_train_melt_ef, y_train)\n",
    "\n",
    "print('[INFO] Best params: {}'.format(model_svr.best_params_))\n",
    "print('[INFO] Best score: {}'.format(-model_svr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "837a0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06749691962168236\n"
     ]
    }
   ],
   "source": [
    "prediction = model_svr.predict(df_x_test_melt_ef)\n",
    "print(rmse(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be11352",
   "metadata": {},
   "source": [
    "tsfreshで抽出した特徴量で学習すると，RMSE=0.67で論文の0.05よりも悪化した．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd8ab5",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* [特徴量変数](https://www.datarobot.com/jp/wiki/feature/)\n",
    "* [特徴量の選択](https://www.datarobot.com/jp/wiki/feature-selection/)\n",
    "* [特徴量エンジニアリング](https://www.datarobot.com/jp/wiki/feature-engineering/)\n",
    "* [データインサイト](https://www.datarobot.com/jp/wiki/insights/)\n",
    "* [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "* [Feature-Engineeringのリンク集めてみた](https://qiita.com/squash/items/667f8cda16c76448b0f4)\n",
    "* [DataFrameで特徴量作るのめんどくさ過ぎる。。featuretoolsを使って自動生成したろ](https://qiita.com/Hyperion13fleet/items/4eaca365f28049fe11c7)\n",
    "* [時系列データから自動で特徴抽出するライブラリ tsfresh](https://qiita.com/yuko1658/items/871df86f99a9134cc9ef)\n",
    "* [特徴量選択のまとめ](https://qiita.com/shimopino/items/5fee7504c7acf044a521)\n",
    "* [機械学習で特徴量を正しく選択する方法](https://rightcode.co.jp/blog/information-technology/feature-selection-right-choice)\n",
    "* [特徴選択とは？機械学習の予測精度を改善させる必殺技「特徴選択」を理解しよう](https://www.codexa.net/feature-selection-methods/)\n",
    "* [Human Activity Recognition Using Smartphones Data Set](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)\n",
    "* [Human Activity Recognition using Smartphone](https://arxiv.org/abs/1401.8212)\n",
    "* [Human Activity Analysis and Recognition from\n",
    "Smartphones using Machine Learning Techniques](https://arxiv.org/abs/2103.16490)\n",
    "* [Human Activity Recognition using Machine Learning](https://github.com/sushantdhumak/Human-Activity-Recognition-with-Smartphones)\n",
    "* [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n",
    "* [統計分析を理解しよう-よく使われている統計分析方法の概要-](https://www.nli-research.co.jp/report/detail/id=61928?site=nli)\n",
    "* [Monash, UEA & UCR Time Series Extrinsic Regression Repository](http://tseregression.org/)\n",
    "* [Flood Modeling Dataset 1](https://zenodo.org/record/3902694#.YTQjG50zaUk)\n",
    "* [Flood Modeling Dataset 2](https://zenodo.org/record/3902696#.YTQktZ0zaUk)\n",
    "* [Flood Modeling Dataset 3](https://zenodo.org/record/3902698#.YTQktZ0zaUk)\n",
    "* [Monash University, UEA, UCR Time Series Extrinsic Regression Archive](https://arxiv.org/abs/2006.10996)\n",
    "* [Time Series Extrinsic Regression](https://arxiv.org/abs/2006.12672)\n",
    "* [ChangWeiTan/TS-Extrinsic-Regression](https://github.com/ChangWeiTan/TS-Extrinsic-Regression)\n",
    "* [製造業：センサデータを機械学習に使う](https://www.datarobot.com/jp/blog/use_manufacturing_sensor_data_for_machine_learning/)\n",
    "* [tsfresh](https://tsfresh.readthedocs.io/en/latest/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
